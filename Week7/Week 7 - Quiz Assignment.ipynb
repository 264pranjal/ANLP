{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 7 - Quiz Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) An RNN is fed with words $w_1,w_2,\\ldots,w_5$, as input at every time step where $t=1,2,\\ldots,5$. At ${t=3}$, what does the RNN predict?\n",
    "\n",
    "- $P(w_4)$\n",
    "- $P(w_3|w_1,w_2)$\n",
    "- $P(w_4|w_1,w_2,w_3)$\n",
    "- None of the above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Answer__: $P(w_4|w_1,w_2,w_3)$\n",
    "\n",
    "- Refer to the RNN Language  model lecture\n",
    "\n",
    "\n",
    "    At time t1, w1 is input and w2 is predicted - P(w2|w1)\n",
    "    At time t2, w2 is input and w3 is predicted - P(w3|w2,w1)\n",
    "    At time t3, w3 is input and w4 is predicted - P(w4|w3,w2,w1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) What are the advantages when characters are used instead of words as input to RNN?\n",
    "\n",
    "- [ ] Vocabulary is restricted to characters and punctuation marks and white space\n",
    "- [ ] Learns words\n",
    "- [ ] Learns spelling of words\n",
    "- [ ] Softmax computation is not required at the output layer\n",
    "- [ ] Does not require word embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Answer__: \n",
    "\n",
    "- See [RNN Based Language Model](https://nbviewer.jupyter.org/github/gymk/ANLP/blob/master/Terms-and-Abbreviations/RNN_Based_Language_Model.ipynb)\n",
    "  - [x] Vocabulary is restricted to characters and punctuation marks and white space\n",
    "  - [x] Learns words\n",
    "  - [x] Learns spelling of words\n",
    "  - [x] Does not require word embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Is the statement \"Vanishing graident problem is easy to address than the exploiding gradient problem\" true?\n",
    "- True\n",
    "- False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Answer__: False\n",
    "\n",
    "- See [v1] Lecture 59"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Consider the following dimensions used in an RNN to answer the question:\n",
    "\n",
    "\t\t\t\t\tEmbedding vector size = 1 × 50\n",
    "\t\t\t\t\tNumber of time states = 1000\n",
    "\t\t\t\t\tHidden layer size = 1 × 100\n",
    "\t\t\t\t\tVocabulary size = 10000\n",
    "\n",
    "What is the size of the context matrix which is connecting the hidden layer and the output layer?\n",
    "\n",
    "- $R^{50\\times1000}$\n",
    "- $R^{100\\times100}$\n",
    "- $R^{100\\times10000}$\n",
    "- $R^{50\\times10000}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Answer__: $R^{100\\times10000}$\n",
    "\n",
    "- Refer [RNN_Backpropagation_Through_Time](https://nbviewer.jupyter.org/github/gymk/ANLP/blob/master/Terms-and-Abbreviations/RNN_Backpropagation_Through_Time.ipynb) $\\Rightarrow$ Size of the RNN Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) The cost function $J(\\theta)$ computed at the output layer in the RNN (consider the notations used in the lecture) is usually represented as a function of –––––\n",
    "- $U,V,h_t$\n",
    "- $U,V,s_t$\n",
    "- $U,V,W$\n",
    "- None of the above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Answer__: $U,V,W$\n",
    "\n",
    "- Refer [v1] $\\Rightarrow$ Lecture 57 $\\Rightarrow$ $15:00$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6) In the BPTT, the $\\displaystyle \\frac{\\partial z_t}{\\partial V}$ is ––––––––––––––––––––\n",
    "- $\\tanh(Uh_{t-1}+Wx_t)$\n",
    "- $Uh_{t-1}+Wx_t$\n",
    "- $1-\\tanh^2(h_t)$\n",
    "- None of the above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Answer__: $\\tanh(Uh_{t-1}+Wx_t)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7) In the BPTT, the $\\displaystyle \\frac{\\partial s_t}{\\partial h_t}$ is –––––––––––––––––––––––––\n",
    "- $Uh_{t-1}+Wx_t$\n",
    "- $\\tanh^2(h_t)$\n",
    "- $1-\\tanh^2(Uh_{t-1}+Wx_t)$\n",
    "- None of the above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Answer__: $1-\\tanh^2(Uh_{t-1}+Wx_t)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8) The matrix of the derivative is known as ––––––––––––––– matrix\n",
    "- Laplacian\n",
    "- Jacobian\n",
    "- Hermitian\n",
    "- Ramaseshan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Answer__: Jacobian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9) Vanishing gradient problem occurs due to ––––––––––––––\n",
    "- Vocabulary size $> 100K$\n",
    "- Hidden layer of size $> 10$\n",
    "- A very long time series as input or long term dependencies\n",
    "- None of the above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Answer__: A very long time series as input or long term dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10) LSTM introduces a –––––––––––––– at the hidden layer\n",
    "- State vector\n",
    "- Memory vector\n",
    "- Word vector\n",
    "- None of the above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Answer__: Memory vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
