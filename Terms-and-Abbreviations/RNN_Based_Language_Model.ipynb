{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN Based Language Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Character based LM - RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Used in keyboard word prediction where while typing the characters, the model has to predict the word and the upcoming words (when a word is typed)\n",
    "- In this language model, character will be the input\n",
    "  - Input will be a __*One-Hot-Vector*__\n",
    "  - Since character will be the input, the size of the vocabulary will be $26$, number of alphabets in English\n",
    "  - Example: For the word $\\texttt{success}$, characters $\\texttt{s}$, $\\texttt{u}$, $\\texttt{c}$, $\\texttt{c}$, $\\texttt{e}$, $\\texttt{s}$ are inputted one by one as a time series\n",
    "    - First $\\texttt{s}$ is given as input and it is expected to give $\\texttt{u}$ as output, if not the error is backpropagated\n",
    "    - Next $\\texttt{u}$ is given as input and it is expected to give $\\texttt{c}$ as output, if not the error is backpropagated\n",
    "    - Above steps are repeated until the stop symbol $\\texttt{\\$}$ is encounted.\n",
    "    - Multiple epochs will be executed until the model is trained.\n",
    "    - Once trained, the model can predict the next character after each current character input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![RNN_Character_Based_LM](images/RNN_Character_Based_LM.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word based Language Model - RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Similar to character based model, we can have Word based LM as well\n",
    "- Input will be a __*One-Hot-Vector*__\n",
    "- We will start inputting one word at a time until encoutering end of sentence symbol\n",
    "- Unlike traditional ANN, this is flexible, in the sense that, you can increase the time slice depending on the lenght of the sentence, and then you can make the system learn, which will give the model, which can be used for prediction\n",
    "  - Theoreticall, we can go for very very long sentence\n",
    "- Normally this model is used for generating text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Word LM | Example of Word LM |\n",
    "| :---: | :---: |\n",
    "| ![RNN_Word_Based_LM_1](images/RNN_Word_Based_LM_1.jpg) | ![RNN_Word_Based_LM_2](images/RNN_Word_Based_LM_2.jpg) |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advantages and Trouble with RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Theoretically, it is possible to store all historical information in the RNN\n",
    "  - Unlike traditional ANN, this is flexible, in the sense that, you can increase the time slice depending on the lenght of the sentence, and then you can make the system learn, which will give the model, which can be used for prediction\n",
    "  - Theoreticall, we can go for very very long sentence\n",
    "  - When we go for a long time series\n",
    "    - We get into the problem of __*Vanishing Gradient*__\n",
    "    - In some cases, we get into the problem of __*Exploding Gradient*__\n",
    "- Vanishing gradient problem - The diminishing value of $\\large \\delta$ makes it difficult to capture the long term memory as we move down the memory lane or layers of hidden nodes\n",
    "  - What is the soltuion?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
