{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling Sequential Data - NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- From [23]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IID - Independent and Identically Distributed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- If we have $n$ data samples, $x^{(1)},x^{(2)},\\ldots,x^{(n)}$, the order in which we use the data for training our machine learning algorithms does not matter\n",
    "  - Example:\n",
    "    - Order of AND, OR Gate trush table as input to Perceptron doesn't matter.\n",
    "      - $[[0,0][0,1],[1,0],[1,1]] [0,0,0,1]$\n",
    "      - $[[1,1],[0,0][0,1],[1,0]] [1,0,0,0]$\n",
    "      - Any order doesn't matter\n",
    "    - Perceptron will learn the parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Sequential Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- What makes sequential data unique, from other data types, is that elements in a sequence appear in a certain order, and are not independent of each other\n",
    "- The $IID$ assumption is not valid in case of _Sequential Data_\n",
    "- _In Sequential Data_, __*order of data matters*__\n",
    "  - Example:\n",
    "    - __*Time Series Data*__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequential Nature of Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Various kind of datasets which exibits sequential nature\n",
    "  - Speech\n",
    "    - Here data is coming as a word boundaried speech words\n",
    "      - To understand the what the speech is about, we need the sequence of words spoke\n",
    "    - Recognizing speech conversation and extracting the context of speech\n",
    "      - Is it a question?\n",
    "      - Is it a command to perform some tasks\n",
    "      - Is it a search request?\n",
    "      - Example\n",
    "        - Amazon Alexa\n",
    "        - Google Assistant\n",
    "        - Apple Siri\n",
    "        - etc.,...\n",
    "  - Documents\n",
    "    - Here data is coming as a sequence of words\n",
    "      - To understand the context, the sequence of words need to be processed\n",
    "    - Understanding what the sentence meaning is?\n",
    "      - Is it a question asking varioud documents related to NLP?\n",
    "  - Videos\n",
    "    - Process incoming video and audio, which is a sequence of data and provide necessary output\n",
    "  - Weather Forecast\n",
    "    - Here historical weather information/report is the sequence\n",
    "    - Given historical weather report, predict weather (whether it is going to rain today or not?)\n",
    "  - Financial - Stock Market\n",
    "    - Here sevaral different variables related to stock market is available as a sequence\n",
    "    - Example\n",
    "      - Given historical stock market, predict market status\n",
    "      - Why the market is down today? Is there any similar situation that can be found from historical information?\n",
    "\n",
    "![Sequential_Nature_Of_Data](images/Sequential_Nature_Of_Data.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Representating Sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $x^{(1)},x^{(2)},\\ldots,x^{(T)}$\n",
    "- Example, time-series data\n",
    "  - $x^{(t)}$ represnts data belonging to particular time $t$\n",
    "  - ![Sequence_Data_Representation](images/Sequence_Data_Representation.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limitations of MLP, CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Standard Neural Network models, MLP (Multi Layer Perceptron), CNN (Convolution Neural Network) are __*not capable of handling the order of input samples*__\n",
    "  - Intuitively, these models __*do not have a memory*__ of the past samples\n",
    "  - Data are passed through _Feed Forward_ and _Backpropagation_ steps, and the weights are updated _independent_ of the order in which the sample is passed\n",
    "- From [24]\n",
    "  - They __*accept fixed-sized vectors*__ as input and __*produce a fixed-size vectors*__ as output\n",
    "    - E.g., Probabilities of different classes\n",
    "  - These models perform this mappingusing a fixed amout of computationanl steps\n",
    "    - i.e., the number of layers in the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Capability of RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- RNN, are __*designed for modeling sequences*__ and are capable of __*remembering past*__ information and __*processing new events*__ accordingly\n",
    "- From [24]\n",
    "  - RNN allows us to operate over _sequence of vectors_\n",
    "    - Sequence in the input\n",
    "    - Sequence in the output\n",
    "    - Or Sequece in both input and output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applications where Sequence Modeling is used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Language Translation\n",
    "- Image Captioning\n",
    "  - Example: [Deep Visual-Semantic Alignments for Generating Image Descriptions](https://cs.stanford.edu/people/karpathy/deepimagesent/)\n",
    "- Text Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categories of Sequence Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- There are different types of sequence modeling exists to develop an appropriate model\n",
    "  - __Many-to-One__\n",
    "    - The input data is a sequence, but the output is a fixed-sized vector, not a sequence\n",
    "      - E.g., _Sentiment Analysis_\n",
    "        The input text-based and the output is class-label\n",
    "  - __One-to-Many__\n",
    "    - The input is in a standard data format, not a sequence, but the output is a sequence\n",
    "      - E.g., _Image Captioning_\n",
    "        - Input is an Image and the output is an English phrase\n",
    "  - __Many-to-Many__\n",
    "    - Both input and output are sequences\n",
    "    - This can be further categorized into whether the input and output are synchronized or not\n",
    "      - __Synchronized__\n",
    "        - E.g., _Video Classification_\n",
    "          - Each frame in a video is labeled\n",
    "      - __Delayed__\n",
    "        - Translating a language into another\n",
    "          - E.g., English to German\n",
    "\n",
    "Image 1             |  Image 2\n",
    ":-------------------------:|:-------------------------:\n",
    "!![Sequence_Model_Categories_1](images/Sequence_Model_Categories_1.jpg)   |  ![Sequence_Model_Categories_2](images/Sequence_Model_Categories_2.jpg)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Study Links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [24]\n",
    "- [Deep Visual-Semantic Alignments for Generating Image Descriptions](https://cs.stanford.edu/people/karpathy/deepimagesent/)\n",
    "- [Find Structure in Time](https://crl.ucsd.edu/~elman/Papers/fsit.pdf)\n",
    "  - Explains how time is represented in NN\n",
    "  - Uses XOR problem as a time series data and details RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding Structure in Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Time underlines many interesting human behaviours\n",
    "- How do we represent the time in connectionist models?\n",
    "  - One approach is to represent time implicitly by its effect on processing rather than  explicitly (as in a spatial representation, not as an additional dimension of the input)\n",
    "  - The current approach is use of recurrent links in order to provide networks with a dynamic memory\n",
    "  - In this approach, hidden unit patterns are fed back to themselves; the internal representations which develop thus reflect task demands in the context of prior internal states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
