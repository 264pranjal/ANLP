{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP Terms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vocabulary\n",
    "\n",
    "- From [v2] Basic Text Processing - Word Tokenization\n",
    "    - Set of Types\n",
    "        - Set of unique tokens in the Text/Corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Type\n",
    "\n",
    "- From [v2] Basic Text Processing - Word Tokenization\n",
    "    - An element of the vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Token\n",
    "\n",
    "- From [v2] Basic Text Processing - Word Tokenization\n",
    "    - An instance of that type in running text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WordNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- From <https://www.guru99.com/wordnet-nltk.html>\n",
    "  - WordNet is a Corpus Reader, a lexical database for English\n",
    "  - It is a semantically oriented dictionary of English\n",
    "  - It can be used to find the\n",
    "    - _meanings of words_\n",
    "    - _Synonyms_\n",
    "    - _Antonyms_\n",
    "  - From WordNet, information about a word or phrase can be calculated as:\n",
    "    - Synonym (Word having the same meaning)\n",
    "    - Hypernyms (The generic terms used to designate a class of specifics(i.e., meal is a breakfast), hyponyms (rice is a meal))\n",
    "    - Holonyms (Proteins, Carbohydrates are part of meal)\n",
    "    - Meronyms (Meal is part of daily food intake)\n",
    "  - WordNet is divided into:\n",
    "    - Noun\n",
    "    - Verb\n",
    "    - Adjective\n",
    "    - Adverb\n",
    "  - Can be used for text analytics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from nltk.corpus import wordnet as wn\n",
    "syns = wn.synsets(\"good\")\n",
    "print(syns)\n",
    "```\n",
    "\n",
    "```\n",
    "[Synset('good.n.01'), Synset('good.n.02'), Synset('good.n.03'), Synset('commodity.n.01'), Synset('good.a.01'), Synset('full.s.06'), Synset('good.a.03'), Synset('estimable.s.02'), Synset('beneficial.s.01'), Synset('good.s.06'), Synset('good.s.07'), Synset('adept.s.01'), Synset('good.s.09'), Synset('dear.s.02'), Synset('dependable.s.04'), Synset('good.s.12'), Synset('good.s.13'), Synset('effective.s.04'), Synset('good.s.15'), Synset('good.s.16'), Synset('good.s.17'), Synset('good.s.18'), Synset('good.s.19'), Synset('good.s.20'), Synset('good.s.21'), Synset('well.r.01'), Synset('thoroughly.r.02')]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from nltk.corpus import wordnet as wn\n",
    "synonyms = []\n",
    "antonyms = []\n",
    "\n",
    "for syn in wn.synsets(\"good\"):\n",
    "    for l in syn.lemmas():\n",
    "        synonyms.append(l.name())\n",
    "        if l.antonyms():\n",
    "            antonyms.append(l.antonyms()[0].name())\n",
    "\n",
    "print('Synonyms: ', set(synonyms))\n",
    "print('Antonyms: ', set(antonyms))\n",
    "```\n",
    "\n",
    "```\n",
    "Synonyms:  {'upright', 'dear', 'safe', 'trade_good', 'adept', 'unspoilt', 'thoroughly', 'full', 'right', 'salutary', 'honorable', 'honest', 'practiced', 'goodness', 'well', 'soundly', 'good', 'beneficial', 'sound', 'undecomposed', 'serious', 'unspoiled', 'skilful', 'near', 'commodity', 'effective', 'respectable', 'just', 'skillful', 'secure', 'proficient', 'estimable', 'in_force', 'expert', 'dependable', 'in_effect', 'ripe'}\n",
    "Antonyms:  {'evil', 'badness', 'ill', 'evilness', 'bad'}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Term-Document-Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- From [v1] Lec 33\n",
    "  - ![Term_Document_Matrix](images/Term_Document_Matrix.jpg)\n",
    "  - Column represents various features of a document\n",
    "  - Row represents the words in the Corpus\n",
    "- From [27]\n",
    "  - More idea on SVD over Term-Document-Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semantic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- From [27]\n",
    "  - Indicates Tenses _(Past vs Present vs Future)_\n",
    "  - Count _(Singular vs Plural)_\n",
    "  - Gender _(Masculine vs Feminine)_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using LSI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- From [v1] Lec 39\n",
    "  - Dimensionality of the matrix is driven by the Singular values which are in Singular Matrix\n",
    "  - If you have SVD over Term-Context Matrix (i.e., Term Document Matrix)\n",
    "    - Left Singular Matrix will contain the word Embeddings\n",
    "    - Right Singular Matrix will contain the Context Embeddings\n",
    "  - ![Word_Embedding](images/Word_Embedding.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- TO DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continuous Bag of Words (CBOW)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Continuous_Bag_Of_Words_Model](images/Continuous_Bag_Of_Words_Model.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skip Gram Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Skip_Gram_Model](images/Skip_Gram_Model.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
