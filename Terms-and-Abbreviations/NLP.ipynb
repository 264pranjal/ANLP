{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP Terms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- From [v2] Basic Text Processing - Word Tokenization\n",
    "    - Set of Types\n",
    "        - Set of unique tokens in the Text/Corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Types and Tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- From [28]\n",
    "  - Consider the following example\n",
    "    - \"Ever tried. Ever failed.\"\n",
    "    - \"No matter. Try again.\"\n",
    "    - \"Fail again. Fail better\"\n",
    "  - There are two tokens of type \"Ever\", two tokens of type \"again\", and two tokens of type \"Fail\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- From [v2] Basic Text Processing - Word Tokenization\n",
    "    - An element of the vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- From [v2] Basic Text Processing - Word Tokenization\n",
    "    - An instance of that type in running text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- From [28]\n",
    "  - Morphology is the study of the internal structures of words\n",
    "  - Often a word is composed of a stem (root) with added affixes (inflections), such as Plurals, Past Tenses\n",
    "    - E.g., _trapped_ is composed of the stem _trap_ and the affix _ed_\n",
    "  - Stemming, as kind of morphological analysis, is the process of reducing inflected words to their stems.\n",
    "  - Normalization increases the recall and reduces precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- From [28]\n",
    "  - The motivation of normalization is that many different strings of characters often convery essentially identical meanins\n",
    "  - Given that we want to get at the meaning that underlies the words, it seems reasonable to normalize suerpficial variations by converting them to the same form.\n",
    "  - Most common types of Normalization\n",
    "    - Case Folding (converting all words to lower case)\n",
    "    - Stemming (reducing inflected words to their stem or root form)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Annotation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- From [28]\n",
    "  - Annotation is the inverse of Normalization\n",
    "  - Just as different strings of characters may have same meaning, it also happens that identical strings of characters may have different meanings, depending on the context.\n",
    "  - Common forms of annotation include\n",
    "    - Part-of-speech tagging (making words according to their parts of speech)\n",
    "    - Word sense tagging (marking ambiguous words according to their intended meanings)\n",
    "    - Parsing (analysing the grammatical structure of sentences and making the words in the sentences according to their grammatical roles)\n",
    "  - Annotation decreases recall and increases precision\n",
    "    - Example, by tagging _program_ as a noun or verb\n",
    "      - We may be able to selectively search for documents that are about the act of computer programming (verb)\n",
    "      - instead of documents that discuss particular computer programs (noun)\n",
    "    - Hence we can increase the precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance measured in Information Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- From [28]\n",
    "  - The performance of an IR system is often measured by _precision_ and _recall_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- From [28]\n",
    "  - The _precision_ of a system is an estimate of the conditional probability that a document is truly relevant to a query, if the system says it is relavant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- From [28]\n",
    "  - The _recall_ of a system is an estimate of the conditional probability that the system will say that a document is relevant to a query, if it is truly relevant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semantic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- From [27]\n",
    "  - Indicates Tenses _(Past vs Present vs Future)_\n",
    "  - Count _(Singular vs Plural)_\n",
    "  - Gender _(Masculine vs Feminine)_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WordNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- From <https://www.guru99.com/wordnet-nltk.html>\n",
    "  - WordNet is a Corpus Reader, a lexical database for English\n",
    "  - It is a semantically oriented dictionary of English\n",
    "  - It can be used to find the\n",
    "    - _meanings of words_\n",
    "    - _Synonyms_\n",
    "    - _Antonyms_\n",
    "  - From WordNet, information about a word or phrase can be calculated as:\n",
    "    - Synonym (Word having the same meaning)\n",
    "    - Hypernyms (The generic terms used to designate a class of specifics(i.e., meal is a breakfast), hyponyms (rice is a meal))\n",
    "    - Holonyms (Proteins, Carbohydrates are part of meal)\n",
    "    - Meronyms (Meal is part of daily food intake)\n",
    "  - WordNet is divided into:\n",
    "    - Noun\n",
    "    - Verb\n",
    "    - Adjective\n",
    "    - Adverb\n",
    "  - Can be used for text analytics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from nltk.corpus import wordnet as wn\n",
    "syns = wn.synsets(\"good\")\n",
    "print(syns)\n",
    "```\n",
    "\n",
    "```\n",
    "[Synset('good.n.01'), Synset('good.n.02'), Synset('good.n.03'), Synset('commodity.n.01'), Synset('good.a.01'), Synset('full.s.06'), Synset('good.a.03'), Synset('estimable.s.02'), Synset('beneficial.s.01'), Synset('good.s.06'), Synset('good.s.07'), Synset('adept.s.01'), Synset('good.s.09'), Synset('dear.s.02'), Synset('dependable.s.04'), Synset('good.s.12'), Synset('good.s.13'), Synset('effective.s.04'), Synset('good.s.15'), Synset('good.s.16'), Synset('good.s.17'), Synset('good.s.18'), Synset('good.s.19'), Synset('good.s.20'), Synset('good.s.21'), Synset('well.r.01'), Synset('thoroughly.r.02')]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from nltk.corpus import wordnet as wn\n",
    "synonyms = []\n",
    "antonyms = []\n",
    "\n",
    "for syn in wn.synsets(\"good\"):\n",
    "    for l in syn.lemmas():\n",
    "        synonyms.append(l.name())\n",
    "        if l.antonyms():\n",
    "            antonyms.append(l.antonyms()[0].name())\n",
    "\n",
    "print('Synonyms: ', set(synonyms))\n",
    "print('Antonyms: ', set(antonyms))\n",
    "```\n",
    "\n",
    "```\n",
    "Synonyms:  {'upright', 'dear', 'safe', 'trade_good', 'adept', 'unspoilt', 'thoroughly', 'full', 'right', 'salutary', 'honorable', 'honest', 'practiced', 'goodness', 'well', 'soundly', 'good', 'beneficial', 'sound', 'undecomposed', 'serious', 'unspoiled', 'skilful', 'near', 'commodity', 'effective', 'respectable', 'just', 'skillful', 'secure', 'proficient', 'estimable', 'in_force', 'expert', 'dependable', 'in_effect', 'ripe'}\n",
    "Antonyms:  {'evil', 'badness', 'ill', 'evilness', 'bad'}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP Matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Token-Document Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- From [28]\n",
    "  - One row for each token\n",
    "    - A row vector for a token has binary values: An element is 1 if the given token appears in the given document and 0 otherwise\n",
    "  - One column for each document\n",
    "  - Used in polysemy, typically in __*WSD(Word Sense Disambiguation)*__ algorithms which deals with word tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Type-Document-Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- From [28]\n",
    "  - One row for each type\n",
    "    - A row vector for a type has integer values: An element is the frequency of the given type in the given document\n",
    "  - One column for each document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Term-Document-Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- From [v1] Lec 33\n",
    "  - ![Term_Document_Matrix](images/Term_Document_Matrix.jpg)\n",
    "  - Column represents various features of a document\n",
    "  - Row represents the words in the Corpus\n",
    "- From [27]\n",
    "  - More idea on SVD over Term-Document-Matrix\n",
    "- From [28]\n",
    "  - Rows corresponds to Terms\n",
    "  - Columns corresponds to Documents\n",
    "  - Use: Similarity of Documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word-Document-Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word-Context-Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Types of matrices used in VSM (Vector Space Model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- From [28]\n",
    "  - TO DO\n",
    "  - Term-Document Matrix\n",
    "  - Word-Context Matrix\n",
    "  - Pari-Pattern Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Term-Document Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- From [28]\n",
    "  - Row vectors corresponds to Terms\n",
    "  - Column vectors corresponds to Documents\n",
    "  - Content of element will be TF-IDF (normally)\n",
    "  - Use: To find the __*Similarity of Documents*__\n",
    "    - The relevance to a query is  given by the similarity of their vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word-Context-Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- From [28]\n",
    "  - Row vectors correspond to words\n",
    "  - Column vector correspond to context given by the words\n",
    "    - Context: words, phrases, sentences, paragraphs, chapters, documents, or more exotic possibilities, such as sequences of characters or patterns\n",
    "  - Use: To find the __*Similarity of Words*__. i.e., measuring __*Attributional Similarity*__\n",
    "    - By looking at row vectors in the Term-Document-Matrix instead of column vectors\n",
    "  - Attributionanl Similarity\n",
    "    - The attribution similarity between two words $a$ and $b$, $sim_a(a,b) \\in \\mathbb{R}$, depends on the degree of correspondence between the properties of $a$ and $b$.\n",
    "    - The more correspondence there is, the greater the attributional similarity\n",
    "  - TO DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pair-Pattern Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- From [28]\n",
    "  - Row vectors correspond to pairs of words, such as $maron : stone$ and $carpenter : wood$\n",
    "  - Column vectors correspond to the patterns in which the pairs co-occur\n",
    "    - such as \"X cuts Y\" and \"X works with Y\"\n",
    "  - Use: To find the __*Relational Similarity of Words*__, measures semnatic similarity of patterns\n",
    "    - To measures the similariy of semantic relationship between pair of words\n",
    "  - Relational Similarity\n",
    "    - The relational similarity between two _pairs_ of words $a : b$ and $c : d$, $sim_r(a:b, c:d) \\in \\mathbb{R}$, depends on the degree of correspondence between the relations of $a : b$ and $c : d$\n",
    "    - The more correspondence there is, the greater the relational similarity\n",
    "      - Example:\n",
    "        - $dog$ and $wolf$ have a relatively _high degree of attributional similarity_\n",
    "        - Where as $dog : bark$ and $cat : meow$ have a relatively _high degree of relational similarity_\n",
    "  - TO DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVD in NLP\n",
    "\n",
    "- From [28]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Latent Meaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- From [28]\n",
    "  - It is a method to discovery latent meaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Noise Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- From [28]\n",
    "  - TO DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sparsity Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- From [28]\n",
    "  - TO DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### High-order Co-occurence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- From [28]\n",
    "  - TO DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using LSI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- From [v1] Lec 39\n",
    "  - Dimensionality of the matrix is driven by the Singular values which are in Singular Matrix\n",
    "  - If you have SVD over Term-Context Matrix (i.e., Term Document Matrix)\n",
    "    - Left Singular Matrix will contain the word Embeddings\n",
    "    - Right Singular Matrix will contain the Context Embeddings\n",
    "  - ![Word_Embedding](images/Word_Embedding.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- TO DO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Continuous Bag of Words (CBOW)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Continuous_Bag_Of_Words_Model](images/Continuous_Bag_Of_Words_Model.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skip Gram Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Skip_Gram_Model](images/Skip_Gram_Model.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polysemy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Meaning in tamil: பலபொருள் ஒருசொல்\n",
    "- Same word having different meanings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [34] describes Polysemy in Tamil, Telugu languages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Named Entity Recognition (NER)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- From v1 Lecture 53\n",
    "  - Named Entity Recognition (NER)\n",
    "    - Example: \"Mr.John is the CEO of the Company. And he had done great things for the company\"\n",
    "      - What does that \"he\" means there in the second sentece?\n",
    "      - Sytem should be able to say that \"he\" refers to the CEO of that company\n",
    "      - It is called NER.\n",
    "    - How many times does the 'CEO' referred in the documennt? Is it possible to find that?\n",
    "      - NER model should be used, which can recognize that person as CEO, wherever he is mentioned as part of the document.\n",
    "  - Data will be Sequential Data\n",
    "  - May be RNN Model required for this kind of problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paraphrase Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- From v1 Lecture 53\n",
    "  - Paraphrase detection - identifying semantically equivalent questions\n",
    "    - A question can be asked in different ways\n",
    "    - All those questions are semantically equivalent\n",
    "    - Paraphrase detection is finding semantically equivalent sentences\n",
    "    - Example: IT Call Center\n",
    "      - They receive calls having various queries, but semantically equivalent\n",
    "      - Company need to find most frequently asked questions (FAQ), so that new joinee can answer those calls\n",
    "      - Here paraphrase detection is required\n",
    "  - Data will be Sequential Data\n",
    "  - May be RNN Model required for this kind of problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Language Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- From v1 Lecture 53\n",
    "  - Language Generation\n",
    "    - 'Given a photograph, you are asked to write a line about the photograph'\n",
    "      - You look at the content of the photograph, say objects and you give some title\n",
    "      - We can use Language Generation Model\n",
    "        - Input is going to be different\n",
    "          - Meaning, the photograph may have 3 object, or 5 object or any number of objects in it\n",
    "          - We should be able to process those without changing or adjusting our neural network size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Translation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- From v1\n",
    "  - Lecture 53\n",
    "    - Given a parallel corpora, we should be able to translate from one language to the other\n",
    "    - We have to do sentence by sentence translation to have correct translation (not word by word translation, which won't give correct translation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speech Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- From v1\n",
    "  - Lecture 53\n",
    "      - Should be able to translation a speech audio file from one language to the other\n",
    "      - Based on the speech, system should be able to recognize what he is speaking about\n",
    "        - Example: Wreck a nice beach or recognize speech\n",
    "          - Based on the context, it should be able to understand that the speaker said \"recognize speech\"\n",
    "        - This can be acheived in NLP, when we have taken words as time-series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spell Checking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- From v1\n",
    "  - Lecture 53\n",
    "    - When you type, you should really be able to figure out the distance between the characters that you have typed so-far and the words that are in the dictionary, start suggesting what is the right word."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Translation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word 2 Word Translation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- From [v1] See Video Lecture 63"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Syntactic Translation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- From [v1] See Video Lecture 63"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semantic Translation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- From [v1] See Video Lecture 63"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interlingua Translation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- From [v1] See Video Lecture 63"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automatic Machine Translation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- From [v1] See Video Lecture 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
