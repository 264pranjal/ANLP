{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [1] [Co-occurrence Matrices and their Applications in Information Science: Extending ACA to the Web Environment](https://www.leydesdorff.net/aca/)\n",
    "- [2] [Discussion of Similarity Metrics](http://mines.humanoriented.com/classes/2010/fall/csci568/portfolio_exports/sphilip/tani.html)\n",
    "- [3] [Tanimoto Coefficient and Fingerprint Generation](https://www.surechembl.org/knowledgebase/84207-tanimoto-coefficient-and-fingerprint-generation)\n",
    "- [4] [Life beyond the Tanimoto coefficient: similarity measures for interaction fingerprints](https://jcheminf.biomedcentral.com/articles/10.1186/s13321-018-0302-y)\n",
    "- [5] [Latent Semantic Indexing Video by Robin Good](https://www.youtube.com/watch?v=LOPY1hPcZEM)\n",
    "- [6] [LSA (Latent Semantic Analysis) Video by Minsuk Heo 허민석](https://www.youtube.com/watch?v=OvzJiur55vo)\n",
    "- [7] [Language modeling and probability](https://cs.brown.edu/courses/cs146/assets/files/langmod.pdf)\n",
    "- [8] [Random variables and probability distributions](http://www.stats.gla.ac.uk/steps/glossary/probability_distributions.html)\n",
    "- [9] [SI485i : NLP Language Models](https://www.usna.edu/Users/cs/nchamber/courses/nlp/f13/slides/set3-LMs.pdf)\n",
    "- [10] [Elementary Probability Theory](http://www2.mta.ac.il/~gideon/courses/nlp/slides/chap02_mathematical_foundations.pdf)\n",
    "- [11] [Basic Concepts in Probability and Information Theory](https://www.cs.bgu.ac.il/~elhadad/nlp17/prob.html)\n",
    "- [12] [NLP: Language Models - CS442/542b: Artificial Intelligence II Prof. Olga Veksler](https://www.csd.uwo.ca/courses/CS4442b/L9-NLP-LangModels.pdf)\n",
    "- [13] [SI485i : NLP Language Models](https://www.usna.edu/Users/cs/nchamber/courses/nlp/f13/slides/set3-LMs.pdf)\n",
    "- [14] [Linear Dependence of Vectors](https://stattrek.com/statistics/dictionary.aspx?definition=linear_dependence_of_vectors)\n",
    "- [15] [Zero-probability events](https://www.statlect.com/fundamentals-of-probability/zero-probability-events)\n",
    "- [16] [Language Modeling - Introduction to N-grams by Dan Jurafsky](https://web.stanford.edu/class/cs124/lec/languagemodeling.pdf)\n",
    "  - Refer [v2]\n",
    "- [17] [ANN, Logical XOR, Backpropagation](http://www.ece.utep.edu/research/webfuzzy/docs/kk-thesis/kk-thesis-html/thesis.html)\n",
    "- [18] [Neural Computing: An Introduction, Beale, R. and Jackson, T, Hilger, Philadelphia, PA, 1991](https://pdfs.semanticscholar.org/7b74/902a4e8a30084a98905f1f4f85c9126d41af.pdf?_ga=2.111745540.1217182228.1567001438-748416405.1567001438)\n",
    "- [19] [Daniel Jurafsky and James H. Martin \"Speech and Language Processing: An Introduction to Natural Language Processing, Computational Linguistics, and Speech Recognition,\" 1st. Upper Saddle River, NJ, USA: Prentice Hall PTR, 2000. isbn: 0130950696](https://web.stanford.edu/~jurafsky/slp3/ed3book.pdf)\n",
    "- [20] [A Study on Basics ofNeural Network](http://www.ijircce.com/upload/2017/april/38_A%20Study%20On%20Basics%20Of%20Neural%20Network%20_Autosaved_%20_1_.pdf)\n",
    "  - A good introduction to various components of NN\n",
    "- [21] [Neural Network FAQ](http://francky.me/aifaq/FAQ-comp.ai.neural-net.pdf)\n",
    "  - Various questions about NN asnwer in this\n",
    "- [22] [Neural Machine Translation](http://mt-class.org/jhu/assets/nmt-book.pdf)\n",
    "  - Another resource detailing how backpropagation works mathematically (easy)\n",
    "  - Slides: http://mt-class.org/jhu/slides/lecture-nn-intro.pdf\n",
    "- [23] [Python Machine Learning, 2nd Edition, by Sebastian Raschka, Vahid Mirjalili, ISBN-10: 1787125939, ISBN-13: 978-1787125933](https://sebastianraschka.com/books.html#python-machine-learning-2nd-edition)\n",
    "  - Chapter 16\n",
    "    - Details why RNN is needed\n",
    "    - Details on What is Sequential Modeling\n",
    "    - Details on what are the limitations on MLP (Multi Layer Perceptron), CNN (Convolutional Neural Network)\n",
    "- [24] [The Unreasonable Effectiveness of Recurrent Neural Networks](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)\n",
    "  - Details limitations of CNN, MLP\n",
    "  - Details on RNN\n",
    "- [25] [Efficient Estimation of Word Representations in Vector Space](https://arxiv.org/pdf/1301.3781.pdf)\n",
    "  - Details CBOW and Skip-Gram Architecture\n",
    "- [26] [Natural Language Processing (almost) from Scratch](https://arxiv.org/pdf/1103.0398v1.pdf)\n",
    "  - Complete and crisp intro to NLP (all kinds of) tasks, models, NN uses\n",
    "- [27] [CS224D: Deep Learning for NLP](https://cs224d.stanford.edu/lecture_notes/notes1.pdf)\n",
    "  - Lecture Notes on 'Introduction to NLP'\n",
    "    - Good overview of all models, more details on\n",
    "      - Context Words\n",
    "      - CBOW\n",
    "      - Skip-Gram\n",
    "      - Negative Sampling\n",
    "- [28] [From Frequency to Meaning: Vector Space Models of Semantics](https://www.jair.org/index.php/jair/article/view/10640/25440)\n",
    "  - Vector Space Models\n",
    "    - Term-Document Matrix\n",
    "    - Word-Context Matrix\n",
    "    - Pair-Pattern Matrix\n",
    "    - SVD and its uses\n",
    "- [29] [Classification and Loss Evaluation - Softmax and Cross Entropy Loss](https://deepnotes.io/softmax-crossentropy)\n",
    "  - Softmax and Cross-Entropy are detailed\n",
    "- [30] [Building a Neural Network from Scratch in Python and in TensorFlow](https://beckernick.github.io/neural-network-scratch/)\n",
    "  - Using Python\n",
    "    - Generates simulated data\n",
    "    - Constructs Neural Network\n",
    "    - Models and Predicts\n",
    "- [31] [word2vec Parameter Learning Explained](https://arxiv.org/abs/1411.2738)\n",
    "  - CBOW and Skip-Gram Model explained in detail with derivatives\n",
    "- [32] [Introduction to the MATH of Neural Networks by Jeff Heaton](https://www.amazon.com/dp/B00845UQL6)\n",
    "  - Author Website <https://www.heatonresearch.com/>\n",
    "    - Artificial Intelligence\n",
    "    - Deep Learning\n",
    "    - Neural Networks\n",
    "    - Kaggle Competition\n",
    "  - Author YouTube channel <https://www.youtube.com/user/HeatonResearch/videos>\n",
    "- [33] [Yoshua Bengio et al. “A Neural Probabilistic Language Model”. In: Journal of Machine Learning Research 3 (Mar. 2003), pp. 1137–1155. issn:1532-4435](http://www.jmlr.org/papers/volume3/bengio03a/bengio03a.pdf)\n",
    "  - Fighting the Curse of Dimensionality with Distributed Representations\n",
    "    - Details how optimization at Softmax can be applied in Word2Vec learning\n",
    "- [34] [On Polysemy in Tamil and other Indian Languages ](http://www.cfilt.iitb.ac.in/gwc2010/pdfs/45_Polysemy_Tamil__Mohanty.pdf) describing Polysemy in Tamil, Telugu languages\n",
    "  - Describes _polysemy_ in Tamil, Telugu languages\n",
    "- [35] [Notes on machine learning](https://peterroelants.github.io/)\n",
    "  - MORE SIMILAR TO LECTURER DIAGRAMS\n",
    "  - How to implement Neual Network\n",
    "  - How to implement RNN\n",
    "  - Cross Entrophy\n",
    "\n",
    "Neural Network Fundamentals with Graphs, Algorithms, and Applications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [v1] [Applied Natural Language Processing by Prof. Ramaseshan R](https://nptel.ac.in/courses/106/106/106106211/)\n",
    "- [v2] [Natural Language Processing - Stanford University (FULL Course) By Dan Jurafsky](https://www.youtube.com/playlist?list=PLLssT5z_DsK8HbD2sPcUIDfQ7zmBarMYv)\n",
    "  - <https://web.stanford.edu/class/cs124/>\n",
    "- [v3] [Perceptron and Logical XOR Problem](https://www.youtube.com/playlist?list=PLWi7UcbOD_0vc_rSRgHAyKig2eMdMTRyo)\n",
    "- [v4] [Lecture Collection | Natural Language Processing with Deep Learning (Winter 2017)](https://www.youtube.com/playlist?list=PL3FW7Lu3i5Jsnh1rnUwq_TcylNr7EkRe6)\n",
    "  - Notes for these are in [27]\n",
    "- [v5] [Neural Networks Demystified by Welch Labs](https://www.youtube.com/playlist?list=PLiaHhY2iBX9hdHaRr6b7XevZtgZRa1PoU)\n",
    "  - Step by Step building python code with brief explanation about\n",
    "    - Scaling, What is Neuron, ANN\n",
    "    - Forward Pass\n",
    "    - Backpropagation\n",
    "    - Gradient Descent\n",
    "    - Trianing\n",
    "    - Overfitting, Testing and Regularization\n",
    "- [v6] [Word Embeddings by macheads101]https://www.youtube.com/watch?v=5PL0TmQhItY\n",
    "  - Website [macheads101](http://macheads101.com/)\n",
    "  - Crips details on how WordEmbedding works\n",
    "  - <https://www.youtube.com/watch?v=OypPjvm4kiA> details how he studied ML/AI - Nice\n",
    "  - Some Links\n",
    "    - MIT OpenCourseware videos on AI: [Artificial Intelligence](https://www.youtube.com/redirect?v=OypPjvm4kiA&redir_token=5WvSIcXw9QayAqcLgvx84dFBO1d8MTU2NzY2NTY5M0AxNTY3NTc5Mjkz&event=video_description&q=http%3A%2F%2Focw.mit.edu%2Fcourses%2Felectrical-engineering-and-computer-science%2F6-034-artificial-intelligence-fall-2010%2Flecture-videos%2F)\n",
    "    - Numerical analysis lectures: [Justin Solomon](https://www.youtube.com/user/justinmsolomon/videos)\n",
    "    - Lots of my AI code: https://github.com/unixpickle/weakai\n",
    "    - Lots of my Numerical Analysis code: (https://github.com/unixpickle/num-analysis)\n",
    "    - Other code showcased in this video:\n",
    "      - <https://github.com/unixpickle/svm-playground>\n",
    "      - <https://github.com/unixpickle/whichlang>\n",
    "      - <https://github.com/unixpickle/heatgrid>\n",
    "    - Papers\n",
    "      - Equilibrated adaptive learning rates for non-convex optimization <https://arxiv.org/pdf/1502.04390v2.pdf>\n",
    "      - Deep learning via Hessian-free optimization <http://www.cs.toronto.edu/~jmartens/docs/Deep_HessianFree.pdf>\n",
    "      - Fast Curvature Matrix-Vector Products for Second-Order Gradient Descent <https://nic.schraudolph.org/pubs/Schraudolph02.pdf>\n",
    "      - Learning Recurrent Neural Networks with Hessian-Free Optimization <http://www.cs.utoronto.ca/~ilya/pubs/2011/HF-RNN.pdf>\n",
    "    - Other Resources\n",
    "      - Neural Networks for Machine Learning <http://www.cs.toronto.edu/~tijmen/csc321/slides/lecture_slides_lec6.pdf>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blogs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [b1] [Raúl Gómez blog](https://gombru.github.io/)\n",
    "  - Various Loss function derivatives\n",
    "  - How CNN works\n",
    "  - Image Classifcation\n",
    "  - LDA over images to classify based on cities\n",
    "  - many more\n",
    "\n",
    "- [b2] https://deepnotes.io/\n",
    "   - Good notes ot Deep Learning\n",
    "   - About CNN,\n",
    "     - Types of CNN Layers\n",
    "   - Deep Clustering\n",
    "- [b3] [Jeff Heaton Research](https://www.heatonresearch.com/jeff/)\n",
    "  - Blog of [32]\n",
    "  - Java, Kaggle, Deep Learning, AI, Neural Networks\n",
    "- [b4] [skymind A.I.Wiki, A Beginner’s Guide to Important Topics in AI, Machine Learning, and Deep Learning.](https://skymind.ai/)\n",
    "  - Various demos and beginner guides to A.I, ML, Spark, ...\n",
    "- [b5] [The Shape of Data - Exploring the geometry behind machine learning, data mining, etc.](https://shapeofdata.wordpress.com/introduction/)\n",
    "  - Focuses on Data Analysis\n",
    "  - ML Algorithms\n",
    "    - Supervised and Unsupervised learning\n",
    "  - Various case studies for those\n",
    "- [b5] [deep ideas - a blog on artificial intelligence, deep learning and cognitive science ](http://www.deepideas.net/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Markdown Help\n",
    "\n",
    "- http://www.math.mcgill.ca/yyang/regression/RMarkdown/example.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Markdown Symbols Help\n",
    "  - <https://www.calvin.edu/~rpruim/courses/s341/S17/from-class/MathinRmd.html>\n",
    "  - <https://csrgxtu.github.io/2015/03/20/Writing-Mathematic-Fomulars-in-Markdown/>\n",
    "  - <https://github.com/Jam3/math-as-code/blob/master/README.md>\n",
    "    \n",
    "- Jupyter Notebook Markdown Help\n",
    "  - <https://www.ibm.com/support/knowledgecenter/en/SSGNPV_1.1.3/dsx/markd-jupyter.html>\n",
    "  - <https://nbviewer.jupyter.org/github/ipython/ipython/blob/2.x/examples/Notebook/Display%20System.ipynb#LaTeX>\n",
    "  - <https://www.math.ubc.ca/~pwalls/math-python/jupyter/latex/>\n",
    "  - <https://kapeli.com/cheat_sheets/LaTeX_Math_Symbols.docset/Contents/Resources/Documents/index>\n",
    "- MathJax basic tutorial and quick reference\n",
    "  - <https://math.meta.stackexchange.com/questions/5020/mathjax-basic-tutorial-and-quick-reference>\n",
    "  - <https://rstudio-pubs-static.s3.amazonaws.com/100749_6b0f55153e71461fa382fd2a2db66507.html>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Juperlab Doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Getting Started with JupyterLab](http://www.blog.pythonlibrary.org/2019/02/05/getting-started-with-jupyterlab/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
