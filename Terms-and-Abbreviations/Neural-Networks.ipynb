{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks\n",
    "\n",
    "- From NLP Perspective\n",
    "    - Another mechanism to process the corpus and get insights out of them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why we need Machine Learning (Neural Nework)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In order to understand the need of NN, we need to understand the limitations of standard algorithms\n",
    "    - __*Standard Algorithm*__: An algorithm is a sequence of instructions to solve a problem\n",
    "        - The steps to solve problems are well defined\n",
    "            - We know _what are the inputs_\n",
    "            - We _know what are the rules to manipulate the input_, and\n",
    "            - We _know what we expect out of program as output_\n",
    "        - Steps are coded in some ordered sequence to transform the input from one form to another\n",
    "        - Rules are unambiguous\n",
    "            - Without specifying rules, we can't solve any problem in _algorithmic fashion_\n",
    "        - Sufficient Knowledge is available to fully solve the problem\n",
    "            - We need to know about the Domain to solve the problem\n",
    "- There are problems whose solutions cannot be formulated using standard rule-based algorithms\n",
    "- Problems that require subtle inputs cannot be solved using standard algorithmic approach - Face Recognition, Speech Recognition, Hand-written character recognition, etc\n",
    "- Finding Examples and using experience gained in similar situations are useful\n",
    "- Examples provide certain underlying patterns\n",
    "- Patterns give the ability to predict some outcome or help in constructing an approximate model\n",
    "- __Learning__ is the key to the ambiguous world"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Given the input and output, finding the relationship between Input and Output\n",
    "    - This learned one is called model\n",
    "    - So that, we can give input similar to the one given as example in learning and get the output\n",
    "- There are problems, where we can't clearly give exact details of input and the rules to find the output.\n",
    "    - In such case, we want the __*Machine*__ to __*Learn*__ from the given input (examples), to find (estimate) the Output\n",
    "- The system starts looking at the (latent) patterns found in the examples, using which it predicts/estimates the outcome\n",
    "- Always their will be new data, so _learning_ is a continuous process and model should be updated accordingly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How ML used in NLP?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Classification\n",
    "- Word Embedding\n",
    "- Learning a Sentence (This is not possible with Probabilistic Language Model)\n",
    "- (How to) Encode a Paragraph\n",
    "- (How to) Encode a Problem Statement\n",
    "- Translation from language to the other\n",
    "    - Can be done with Statistical Machine Translation models, but NN based models have advatange\n",
    "- Modeling conversations - Chatbot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- From [17]\n",
    "    - Perceptron is the basic element of Neural Network\n",
    "    - From where Neural Network started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent\n",
    "\n",
    "- Helps in answering\n",
    "    - How do we iterate to realy get to the solution by descending down /ascending up the slope using Gradient Descendent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- From [v1] Week 3, Lec 2\n",
    "    - __Classification__ is the task of assigning predefine dis-joint categories to objects\n",
    "    - Example\n",
    "        - Detect $\\text{Spam emails}$\n",
    "        - Find the set of $\\text{mobile phones < Rs.10000 and received  $5*$ reviews}$\n",
    "            - In these kind of classification NER will be used to extract the features and then classification will be performed over the extracted features\n",
    "        - Identify the category of the incoming document as Sports, Politics, Entertainment or Business\n",
    "        - Determine whether a movie review is a Positive of Negative Review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The input is a collection of records\n",
    "- Each rechord is represented by a tuple ($x$,$y$)\n",
    "- $x=x_1,x_2,...,x_n$ and $y=y_1,y_2,...y_n$ are the input features and the classes respectively\n",
    "- Example\n",
    "    - $x \\in R^{2}$ is a vector - the of observed variables\n",
    "    - ($x$,$y$) are related by an unknown function. The goal is to estimate the unknown function $g(.)$ also known as a classifier function, such that $g(x) = f(x), \\forall x$\n",
    "    \n",
    "    ![Classification_Model](images/Classification_Model.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What does the Classifier Fucntion do?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Assuming we have a linearly separable $x$, the classifier function $g(.)$ implements decision rule\n",
    "    - Fitting a Straight Line to a given data set requires two parameters $(w_0 $ $and$  $w)$\n",
    "        - $w_0$ is the bias\n",
    "            - It is the distance of the line from the origin\n",
    "        - $w$ is the weight\n",
    "            - It is the orientation of the line\n",
    "        - Both $w_0$ and $w$ are called as _Model Parameters_\n",
    "        - __*Fitting the Line*__: This decision doubary line is estimated in a iterative fashion\n",
    "            - Using the errors that we are caulcualted after fitting a line in each iteration\n",
    "            - This fitment is leart during the above iterative process\n",
    "    - The decision rule divides the data space into two sub-spaces separating two classes using a boundary\n",
    "    - The distance of the boundary from the origin $= \\frac{w_0}{\\parallel w \\parallel}$\n",
    "    - Distance of any point from the boundary $=d=\\frac{g(x)}{\\parallel w \\parallel}$\n",
    "    \n",
    "    ![Classifier_Function](images/Classifier_Function.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lineary Separable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- From https://en.wikipedia.org/wiki/Linear_separability\n",
    "    - If a set of points can be separated by using a line (a hyperplane in higher dimension), then we can say that the points are __*lineary separable*__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Models for Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The goal of classification is to take a vector $x$ and assign it to one of the $N$ discrete $\\mathbb{C}_n$, where $n=1,2,3,...,N$\n",
    "    - The classes are disjoint and an input is assigned to only one class\n",
    "    - The input space is divided into _decision regions_\n",
    "    - The boundaries are called a _decision boundaries or decision surfaces_\n",
    "    - In general, if the input space is $N$ dimensional, then $g(x)$ would define $N-1$ hyperplane"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geomentry of the Linear Discrimminant Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Geomentry_of_the_Linear_Discriminant_Function](images/Geomentry_of_the_Linear_Discriminant_Function.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Boundary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1D-Decision Boundary for OR Gate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The decision regions are separated by a hyperplane and it is defined by $g(x) - 0$.\n",
    "- This separates linearly separable classes $\\mathbb{C}_1$ and $\\mathbb{C}_2$\n",
    "- The $OR$ Gate _Truth Table_\n",
    "\n",
    "| $x_1$ | $x_2$ | y |\n",
    "|-------|-------|---|\n",
    "| 0     | 0     | 0 |\n",
    "| 0     | 1     | 1 |\n",
    "| 1     | 0     | 1 |\n",
    "| 1     | 1     | 1 |\n",
    "\n",
    "- If any of the input feature $x_1$ or $x_2$ has 1, then result is $1$\n",
    "- Below diagram depicts the boundary line for this OR gate\n",
    "    ![1D_Decision_Boundary_For_OR_Gate](images/1D_Decision_Boundary_For_OR_Gate.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1D-Decision Boundary for AND Gate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The decision regions are separated by a hyperplane and it is defined by $g(x) = 0$.\n",
    "- This separates linearly separable classes $\\mathbb{C}_1$ and $\\mathbb{C}_2$\n",
    "- The $AND$ Gate _Truth Table_\n",
    "\n",
    "| $x_1$ | $x_2$ | y |\n",
    "|-------|-------|---|\n",
    "| 0     | 0     | 0 |\n",
    "| 0     | 1     | 0 |\n",
    "| 1     | 0     | 0 |\n",
    "| 1     | 1     | 1 |\n",
    "\n",
    "- We will have 1 only when both $x_1$ and $x_2$ are 1\n",
    "- The boundary line for this $AND$ gate will similar to the one below\n",
    "\n",
    "    ![1D_Decision_Boundary_For_AND_Gate](images/1D_Decision_Boundary_For_AND_Gate.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Boundary for Sentiments - NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The concept of decision boundary can be applied to NLP as well\n",
    "- Let us consider some positive and negative sentiment terms which are contained in two classes $\\mathbb{C}_P$ and $\\mathbb{C}_N$\n",
    "    - $\\mathbb{C}_P = [\\text{achieve efficient improve profitable}] = +1$\n",
    "    - $\\mathbb{C}_N = [\\text{termination penalties misconduct serious}] = -1$\n",
    "    \n",
    "    ![Decision_Boundary_For_Sentiments](images/Decision_Boundary_For_Sentiments.jpg)\n",
    "    \n",
    "- __*Note*__\n",
    "    - Here inputs are texts\n",
    "    - We need to transform the input for finding the decision boundary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Boundary - Variation of $W_J$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The slope (weight) of the line is decided by varaition sof $W_J$\n",
    "    - During fitment of a line/ learning the model, the slope of the line need to be adjusted to have _line of fit_\n",
    "    - So, $W_J$ need to be adjustedbased on the errors calcualted after each iteration during fitment\n",
    "\n",
    "    ![Decision_Boundary_Variation_of_W_J](images/Decision_Boundary_Variation_of_W_J.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Boundary - Variation of Bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The distance of the decision boundary from origin is decided by bias ($w_0$)\n",
    "    - During fitment, line/hyperplane need to be moved to have apprximate decision boundary which splits the input to decision regions\n",
    "    - So, bias $w_0$ also need to be variated during iterative process of learning/fitment\n",
    "- The contribution of bias to the creation of the decision boundary\n",
    "\n",
    "    ![Decision_Boundary_Variation_of_Bias](images/Decision_Boundary_Variation_of_Bias.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Boundary and Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Example showing the iterative process of fitting the line using _Gradient Descent_\n",
    "    - Assume we have the following\n",
    "        - Input: 10 points are taken as input, shown in picture as $\\perp$\n",
    "        - Output: Assume output classes are well defined and well known\n",
    "    - What we don't know is how to fit the line so that decision region(s) are created to each class\n",
    "        - This fitment has to be learnt during the iterative process\n",
    "- Picture shows the fitment of line in 10 iterations\n",
    "    - Let $y$ be our target\n",
    "        - The green line which goes over $\\perp$ in the left diagram\n",
    "    - let $\\hat{y}$ is estimate\n",
    "        - The first line is shown in blue color (parallel to x-axis)\n",
    "    - Goal is to have $y-\\hat{y} \\approx 0$\n",
    "        - That is the error should reach the _minima_, or no more change that can be brought to the model parameters, then we can stop the iteration\n",
    "    - In each iteration error $y-\\hat{y}$ is calcualted and it is propogated back to the model and ask the model to learn the parameter ($w$ and $w_0$ keeps changing in each iteration)\n",
    "    \n",
    "Image 1             |  Image 2\n",
    ":-------------------------:|:-------------------------:\n",
    "![Decision_Boundary_And_Gradient_Descent](images/Decision_Boundary_And_Gradient_Descent.jpg)  |  ![Decision_Boundary_And_Gradient_Descent_2](images/Decision_Boundary_And_Gradient_Descent_2.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lineary Separable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Is below data libearyly separable?\n",
    "\n",
    "    ![Linearly_Separable](images/Linearly_Separable.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc-autonumbering": true,
  "toc-showcode": true,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
