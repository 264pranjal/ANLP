{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 3 - Quiz Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Assume that the chain rule is used to compute the joint probability of the sentence $P('I \\; got \\; this \\; one') $. The products of probabilities are represented by\n",
    " $P(got|I)×P(this|I,got)×P(one|I,got,this)$\n",
    " - True\n",
    " - False "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Answer__: False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It should be  $P(I)×P(got|I)×P(this|I,got)×P(one|I,got,this)$\n",
    "\n",
    "Probability of the sentence $W$:\n",
    "\n",
    "> $P(W) = P(w_1, w_2, ..., w_n)$\n",
    "\n",
    "Chain Rule:\n",
    "\n",
    "> $P(w_1, w_2, ..., w_n) = P(w_1)P(w_2|x_1)...P(w_n|w_1,...w_{n-1})$\n",
    "\n",
    "> $P('I \\; got \\; this \\; one') = P('I', 'got', 'this', 'one'')$\n",
    "\n",
    "> $P('I \\; got \\; this \\; one') = P('I') × P('got' | 'I') × P('this' | 'I \\;  got') × P('one' | 'I \\;  got \\;  this')$\n",
    "\n",
    "Markove Assumption:\n",
    "\n",
    ">  $P('I \\; got \\; this \\; one') = P('I') × P('got' | 'I') × P('this' | 'got') × P('one' | 'this')$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Assume that the language model is evaluated as given below\n",
    "\n",
    "$\\phi(W) =  \\sqrt[n]{\\frac{1}{{P(w_1,w_2,\\ldots, w_n)}}}$\n",
    "\n",
    "*__Note:__*  $n$ is the number of words in the sentence.\n",
    "\n",
    "Smoothing will be used if the denominator →0. \n",
    "\n",
    "Is the statement $\"Minimizing \\; ϕ(W) \\; is \\; same \\; as \\; maximizing \\; the \\; probability \\; P(w_1,w_2,…,w_n) \\; of \\; the \\; sentence\"$ true?\n",
    "- True\n",
    "- False"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "__Answer__: True\n",
    "\n",
    "Refer [9], about Perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2459802354008653\n",
      "1.0846887957840605\n",
      "1.0504095205335795\n",
      "\n",
      "1.105132015639037\n",
      "1.037642609845368\n",
      "1.0226063306698965\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def get_nth_root(num,root):\n",
    "    '''\n",
    "    Computers Nth root over the given num and returns it\n",
    "    '''\n",
    "    answer = num ** (1/root) \n",
    "    return answer\n",
    "\n",
    "def getPerplexityMetric(n, p):\n",
    "    '''\n",
    "    Input:\n",
    "        n: number of words in the sentence\n",
    "        p: probability of the sentence\n",
    "    Output:\n",
    "        Returns perplexity\n",
    "    '''\n",
    "    return get_nth_root(1/p, n)\n",
    "\n",
    "print(getPerplexityMetric(5, 0.333))\n",
    "print(getPerplexityMetric(5, 0.666))\n",
    "print(getPerplexityMetric(5, 0.782))\n",
    "print()\n",
    "print(getPerplexityMetric(11, 0.333))\n",
    "print(getPerplexityMetric(11, 0.666))\n",
    "print(getPerplexityMetric(11, 0.782))\n",
    "\n",
    "# From below, we can see Minimizing Perplexity, increases sentence Probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Select one of the following bigram probabilities that represents the sentence\n",
    "\n",
    "    I love dogs\n",
    "    \n",
    "(i)  __&lt;\\S&gt; I love dogs&lt;/S&gt;__ P (I)· P (love | I) · P (dogs | I love)\n",
    "\n",
    "(ii) P (<S>) · P (I | __&lt;S&gt;__) · P (love | __&lt;S&gt;__ I) · P (dogs | I love) · P (__&lt;/S&gt;__ | love dogs)\n",
    "    \n",
    "(iii) P (I | __&lt;S&gt;__) · P (love | I) · P (dogs | love) · P (__&lt;/S&gt;__ | dogs)\n",
    "    \n",
    "    - a\n",
    "    - b\n",
    "    - c\n",
    "    - d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Answer__: c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) The table given below contains some of the bigram frequencies of $(determine,w_i)$ where $w_i$ represents every word in the column\n",
    "\n",
    "| first word |  the  | how | this   | a     | his    |\n",
    "|------------|:-----:|:---:|--------|-------|--------|\n",
    "| determine  | 0.115 | 0   | 0.0125 | 0.006 | 0.0013 |\n",
    "\n",
    "What is the conditional probability of $P(his|determine)$ if the probability of $determine$ as the starting word is 0.6?\n",
    "- 0.0031\n",
    "- 0.0022\n",
    "- 0.0122\n",
    "- 0.0128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Answer__: 0.0022\n",
    "\n",
    "*Derivation:*\n",
    "\n",
    "Given $E_1 = determine$, $E_2 = his$, $P(E_1, E_2) = 0.0013$, $P(E1) = 0.6$\n",
    "\n",
    "Conditional Probability Formula: $P(E_2 | E_1) = \\frac{P(E_1,E_2)} {P(E_1)}$ if $P(E_1) > 0$\n",
    "\n",
    "$P(his | determine) = \\frac{P(determine,his)} {P(determine)}$\n",
    "\n",
    "$P(his | determine) = \\frac{0.0013} {0.6}$\n",
    "\n",
    "0.00216666666666666666666666666667"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) Assuming that a language model assigns the following conditional probabilities to a 4-word sentence (S)=0.01212. What is the perplexity? \n",
    "\n",
    "    Note: Perplexity is defined in question 2.\n",
    "    \n",
    "- 2.41\n",
    "- 3.14\n",
    "- 4.35\n",
    "- 3.014"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Answer__: d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0138688166390875\n"
     ]
    }
   ],
   "source": [
    "print(getPerplexityMetric(4, 0.01212))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6) Consider the following three sentences\n",
    "\n",
    "     Ram read a novel\n",
    "     Raj read a journal\n",
    "     Rai read a book\n",
    "\n",
    "What is the bigram probability of the sentence\n",
    "\n",
    "    Ram read a book?\n",
    "\n",
    "Include start and end symbols in your calculations\n",
    "\n",
    "- 0.06\n",
    "- 0.2222\n",
    "- 0.1111\n",
    "- 0.0556"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Answer__: 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7) Consider the following three sentences\n",
    "\n",
    "    Ram read a novel\n",
    "    Raj read a journal\n",
    "    Rai read a book\n",
    "\n",
    "What is the trigram probability of the sentence\n",
    "\n",
    "    Ram read a book?\n",
    "\n",
    "Include start and end symbols in your calculations\n",
    "- 0.06\n",
    "- 0.2222\n",
    "- 0.1111\n",
    "- 0.0556\n",
    "- None of the above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Answer__: 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ram read a novel\n",
      "Raj read a journal\n",
      "Rai read a book\n",
      "0 ['<S>', 'ram', 'read', 'a', 'novel', '<\\\\S>']\n",
      "1 ['<S>', 'raj', 'read', 'a', 'journal', '<\\\\S>']\n",
      "2 ['<S>', 'rai', 'read', 'a', 'book', '<\\\\S>']\n",
      "\n",
      " Building Bigram Model ...\n",
      "For <S>:\n",
      "\t<S> ram 1\n",
      "\t<S> raj 1\n",
      "\t<S> rai 1\n",
      "For ram:\n",
      "\tram read 1\n",
      "For read:\n",
      "\tread a 3\n",
      "For a:\n",
      "\ta novel 1\n",
      "\ta journal 1\n",
      "\ta book 1\n",
      "For novel:\n",
      "\tnovel <\\S> 1\n",
      "For raj:\n",
      "\traj read 1\n",
      "For journal:\n",
      "\tjournal <\\S> 1\n",
      "For rai:\n",
      "\trai read 1\n",
      "For book:\n",
      "\tbook <\\S> 1\n",
      "Count:  3.0\n",
      "Count:  1.0\n",
      "Count:  3.0\n",
      "Count:  3.0\n",
      "Count:  1.0\n",
      "Count:  1.0\n",
      "Count:  1.0\n",
      "Count:  1.0\n",
      "Count:  1.0\n",
      "Query Bi  <S> ram 0.3333333333333333\n",
      "Query Bi  ram read 1.0\n",
      "Query Bi  read a 1.0\n",
      "Query Bi  a book 0.3333333333333333\n",
      "Query Bi  book <\\S> 1.0\n",
      "0.1111111111111111\n",
      "Ram read a novel\n",
      "Raj read a journal\n",
      "Rai read a book\n",
      "0 ['<S>', '<S>', 'ram', 'read', 'a', 'novel', '<\\\\S>', '<\\\\S>']\n",
      "1 ['<S>', '<S>', 'raj', 'read', 'a', 'journal', '<\\\\S>', '<\\\\S>']\n",
      "2 ['<S>', '<S>', 'rai', 'read', 'a', 'book', '<\\\\S>', '<\\\\S>']\n",
      "\n",
      " Building Trigram Model ...\n",
      "['<S>', '<S>', 'ram', 'read', 'a', 'novel', '<\\\\S>', '<\\\\S>']\n",
      "['<S>', '<S>', 'raj', 'read', 'a', 'journal', '<\\\\S>', '<\\\\S>']\n",
      "['<S>', '<S>', 'rai', 'read', 'a', 'book', '<\\\\S>', '<\\\\S>']\n",
      "Count:  3.0\n",
      "Count:  1.0\n",
      "Count:  1.0\n",
      "Count:  3.0\n",
      "Count:  1.0\n",
      "Count:  1.0\n",
      "Count:  1.0\n",
      "Count:  1.0\n",
      "Count:  1.0\n",
      "Count:  1.0\n",
      "Count:  1.0\n",
      "Count:  1.0\n",
      "Count:  1.0\n",
      "Count:  1.0\n",
      "For <S> <S>:\n",
      "\t<S> <S> ram 0.3333333333333333\n",
      "\t<S> <S> raj 0.3333333333333333\n",
      "\t<S> <S> rai 0.3333333333333333\n",
      "For <S> ram:\n",
      "\t<S> ram read 1.0\n",
      "For ram read:\n",
      "\tram read a 1.0\n",
      "For read a:\n",
      "\tread a novel 0.3333333333333333\n",
      "\tread a journal 0.3333333333333333\n",
      "\tread a book 0.3333333333333333\n",
      "For a novel:\n",
      "\ta novel <\\S> 1.0\n",
      "For novel <\\S>:\n",
      "\tnovel <\\S> <\\S> 1.0\n",
      "For <S> raj:\n",
      "\t<S> raj read 1.0\n",
      "For raj read:\n",
      "\traj read a 1.0\n",
      "For a journal:\n",
      "\ta journal <\\S> 1.0\n",
      "For journal <\\S>:\n",
      "\tjournal <\\S> <\\S> 1.0\n",
      "For <S> rai:\n",
      "\t<S> rai read 1.0\n",
      "For rai read:\n",
      "\trai read a 1.0\n",
      "For a book:\n",
      "\ta book <\\S> 1.0\n",
      "For book <\\S>:\n",
      "\tbook <\\S> <\\S> 1.0\n",
      "Query Tri  <S> <S> ram 0.3333333333333333\n",
      "Query Tri  <S> ram read 1.0\n",
      "Query Tri  ram read a 1.0\n",
      "Query Tri  read a book 0.3333333333333333\n",
      "Query Tri  a book <\\S> 1.0\n",
      "Query Tri  book <\\S> <\\S> 1.0\n",
      "0.1111111111111111\n"
     ]
    }
   ],
   "source": [
    "from ngram_lm import NGramLM\n",
    "\n",
    "corpus = [\n",
    "    'Ram read a novel', \\\n",
    "    'Raj read a journal', \\\n",
    "    'Rai read a book'\n",
    "]\n",
    "query = 'Ram read a book'\n",
    "\n",
    "bi_lm = NGramLM(corpus,True,True)\n",
    "bi_lm.buildBiGramModel()\n",
    "print(bi_lm.getBiGramProbability(query))\n",
    "\n",
    "# Add additional start/stop\n",
    "tri_lm = NGramLM(corpus,True,True,2)\n",
    "tri_lm.buildTriGramModel()\n",
    "print(tri_lm.getTriGramProbability(query))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8) In Naive Bayes classification, Posterior probability is estimated for predicting the class?\n",
    "- True\n",
    "- False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Answer__: True\n",
    "\n",
    "Refer <https://www.saedsayad.com/naive_bayesian.htm> for explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9) The following table contains the extracted features of emails and their classes (Spam and not Spam). The prior probabilities of the two classes (Spam,not Spam) = (0.57, 0.43) true?\n",
    "\n",
    "| # of Words/# of capitalized words | Subject in all capital letters | # URLs > 3 | Spam |\n",
    "|-----------------------------------|--------------------------------|------------|------|\n",
    "| No                                | No                             | 0          | No   |\n",
    "| No                                | No                             | 5          | No   |\n",
    "| Yes                               | Yes                            | 4          | Yes  |\n",
    "| Yes                               | No                             | 4          | Yes  |\n",
    "| Yes                               | No                             | 0          | No   |\n",
    "| No                                | Yes                            | 7          | Yes  |\n",
    "| Yes                               | No                             | 0          | No   |\n",
    "\n",
    "- Yes\n",
    "- No"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Answer__: No\n",
    "\n",
    "- Count of Total Emails: 7\n",
    "- Count of Spam Emails: 3\n",
    "- Count of NoSpam Emails: 4\n",
    "\n",
    "$P(Spam) = \\frac{Count(Spam Emails)}{Count(Total Emails} = \\frac{3}{7} = 0.43$\n",
    "\n",
    "$P(NoSpam) = \\frac{Count(NoSpam Emails)}{Count(Total Emails} = \\frac{4}{7} = 0.57$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
