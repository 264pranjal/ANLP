{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 5 - Quiz Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) The derivative of $\\sigma(x)$ is\n",
    "\n",
    "- $(1 - \\sigma(x))$\n",
    "- $\\sigma(x)(1 - \\sigma(x))$\n",
    "- $\\displaystyle \\frac{1}{1+e^{-x}}$\n",
    "- None of the above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Answer__: [$\\sigma(x)(1 - \\sigma(x))$](https://beckernick.github.io/sigmoid-derivative-neural-network/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>__ANN Info Use the data given below to answer questions 2-4, 9,10.__</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 4 words in the vocabulary and each one of them is represented by a one-hot-vector.\n",
    "\n",
    "The ANN uses the one-hot-vector as the feature vector in the input layer.\n",
    "\n",
    "There is no bias in this ANN.\n",
    "\n",
    "What is the net activation of the hidden layer correspoding to the 3rd word in the vocabulary, if the weights connecting the input layer and the hidden layer are given as below\n",
    "\n",
    "$\\textbf{W}^T = \\begin{pmatrix}\n",
    "\t\t\t0.1 &0.7&0.3 &0.11\\\\ \n",
    "\t\t\t0.4 &0.3&0.01 &0.5\n",
    "\t\t\\end{pmatrix}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Code__:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "np.set_printoptions(precision=2) # https://stackoverflow.com/questions/2891790/how-to-pretty-print-a-numpy-array-without-scientific-notation-and-with-given-pre\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "def activationLevel(X,W,b):\n",
    "    return np.dot(W.T,X) + b\n",
    "\n",
    "X = np.array([[0],[0],[1],[0]])\n",
    "W = np.array([[0.1, 0.7, 0.3, 0.11], [0.4, 0.3, 0.01, 0.5]]).T\n",
    "b = 0.0 # given in description\n",
    "#print(X)\n",
    "#print(W)\n",
    "z_net_value = activationLevel(X,W,b)\n",
    "print('\\nz net value: ')\n",
    "print(z_net_value)\n",
    "\n",
    "def sigmoid(net_val):\n",
    "    return 1.0/(1.0 + np.exp(-(net_val)))\n",
    "h_val = sigmoid(z_net_value)\n",
    "print('\\nh val: ')\n",
    "print(h_val)\n",
    "\n",
    "V = np.array([[0.2, 0.5], [0.1, 0.003], [0.01, 0.05], [0.11, 0.12]]).T\n",
    "#print(h_val)\n",
    "#print(V)\n",
    "u_net_val = activationLevel(h_val,V,b)\n",
    "print('\\nu net value: ')\n",
    "print(u_net_val)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Output__:\n",
    "\n",
    "```python\n",
    "z net value: \n",
    "[[0.3 ]\n",
    " [0.01]]\n",
    "\n",
    "h val: \n",
    "[[0.57]\n",
    " [0.5 ]]\n",
    "\n",
    "u net value: \n",
    "[[0.37]\n",
    " [0.06]\n",
    " [0.03]\n",
    " [0.12]]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) The size of the hidden layer is 4\n",
    "\n",
    "- True\n",
    "- False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Answer__: False\n",
    "\n",
    "- 4 Input neurons, so we will have 4 synapses (weight) elements to each neuron\n",
    "- Assume it is connected to 1 neuron\n",
    "  - Each synapses will have its own weight to that neuron\n",
    "    - $\\textbf{W}_{4 \\times 1}$\n",
    "- For 2 neurons\n",
    "  - we will ahve two weight vectors corresponding to each neuron\n",
    "    - $\\textbf{W}_{4 \\times 2}$\n",
    "- ${\\textbf{W}^T}_{2 \\times 4} \\rightarrow {\\textbf{W}}_{4 \\times 2}$\n",
    "- So it is 2 neurons, hence False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) What is the net value ($\\textbf{z}$) of the hidden layer?\n",
    "\n",
    "- [0.11 0.5]\n",
    "- [0.3 0.11]\n",
    "- [0.3 0.01]\n",
    "- [0.7 0.3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Answer__: $[0.3\\quad0.01]$\n",
    "\n",
    "$\\textbf{X} = \\begin{pmatrix}\n",
    "\t\t\t0\\\\\n",
    "            0\\\\\n",
    "            1\\\\\n",
    "            0\n",
    "\t\t\\end{pmatrix}\n",
    "%\n",
    "\\textbf{W}^T = \\begin{pmatrix}\n",
    "\t\t\t0.1 &0.7&0.3 &0.11\\\\ \n",
    "\t\t\t0.4 &0.3&0.01 &0.5\n",
    "\t\t\\end{pmatrix} = [0.3\\quad0.01]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) What is the value of $\\textbf{h}$ rounded to 2 decimals, if $\\textbf{h} = \\sigma(\\textbf{z})$\n",
    "\n",
    "- [0.57 0.50]\n",
    "- [0.53 0.62]\n",
    "- [0.67 0.57]\n",
    "- [0.53 0.60]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Answer__: $[0.57\\quad0.50]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) In the CBOW ANN Model, context words are predicted\n",
    "\n",
    "- True\n",
    "- False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Answer__: False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6) In the Skip-Gram ANN Model, context words are input as feature vectors\n",
    "\n",
    "- True\n",
    "- False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Answer__: False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7) In Skip-Gram and CBOW ANN models, the input layer size is equal to the output layer size\n",
    "\n",
    "- True\n",
    "- False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Answer__: True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8) In the Word2Vec Model, posterior probability of words in the vocabulary are obtained as the predicted output\n",
    "\n",
    "- True\n",
    "- False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Answer__: True\n",
    "\n",
    "- Refer [A simple Word2vec tutorial](https://medium.com/@zafaralibagh6/a-simple-word2vec-tutorial-61e64e38a6a1>)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9) What would be size of the output layer for the Word2Vec Model, if the information given above (<u>__ANN Info__</u>) is used in designing the network?\n",
    "\n",
    "- 2\n",
    "- 3\n",
    "- 4\n",
    "- Can be of any size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Answer__: 4\n",
    "\n",
    "For Both CBOW and Skip-Gram models, the number of neurons in output layer should be same as input layer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10) Consider the following information in addition to the information given above (<u>__ANN Info__</u>).\n",
    "\n",
    "$V^{T} = \\begin{pmatrix}\n",
    "\t \t\t\t0.2&0.5\\\\\n",
    "\t \t\t\t0.1&0.003\\\\\n",
    "\t \t\t\t0.01&0.05\\\\\n",
    "\t \t\t\t0.11&0.12\n",
    "\t\t\\end{pmatrix}$\n",
    "\n",
    "Use the value of $h$ obtained in question 4 to compute net output $u$. The value of $u = [0.36\\quad0.07\\quad0.03\\quad0.52]$\n",
    "\n",
    "- True\n",
    "- False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Answer__: False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
